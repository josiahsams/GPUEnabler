//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21554848
// Cuda compilation tools, release 8.0, V8.0.61
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_35
.address_size 64

	// .globl	getClusterCentroids
.extern .shared .align 8 .b8 local_means[];

.visible .entry getClusterCentroids(
	.param .u32 getClusterCentroids_param_0,
	.param .u64 getClusterCentroids_param_1,
	.param .u64 getClusterCentroids_param_2,
	.param .u64 getClusterCentroids_param_3,
	.param .u32 getClusterCentroids_param_4,
	.param .u32 getClusterCentroids_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<28>;
	.reg .f64 	%fd<16>;
	.reg .b64 	%rd<19>;


	ld.param.u32 	%r14, [getClusterCentroids_param_0];
	ld.param.u64 	%rd8, [getClusterCentroids_param_1];
	ld.param.u64 	%rd9, [getClusterCentroids_param_2];
	ld.param.u64 	%rd10, [getClusterCentroids_param_3];
	ld.param.u32 	%r12, [getClusterCentroids_param_4];
	ld.param.u32 	%r13, [getClusterCentroids_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r1, %r2, %r3;
	setp.ge.s32	%p1, %r4, %r14;
	@%p1 bra 	BB0_7;

	mov.u32 	%r25, 0;
	setp.lt.s32	%p2, %r12, 1;
	@%p2 bra 	BB0_6;

	cvta.to.global.u64 	%rd1, %rd10;
	cvta.to.global.u64 	%rd11, %rd8;
	mul.lo.s32 	%r19, %r13, %r4;
	mul.wide.s32 	%rd12, %r19, 8;
	add.s64 	%rd2, %rd11, %rd12;
	mov.f64 	%fd12, 0d7FEFFFFFFFFFFFFF;
	mov.u32 	%r17, 0;
	mov.u32 	%r22, %r17;
	mov.u32 	%r27, %r17;

BB0_3:
	mul.lo.s32 	%r21, %r13, %r22;
	mul.wide.s32 	%rd13, %r21, 8;
	add.s64 	%rd17, %rd1, %rd13;
	mov.f64 	%fd14, 0d0000000000000000;
	mov.f64 	%fd15, %fd14;
	setp.lt.s32	%p3, %r13, 1;
	mov.u64 	%rd18, %rd2;
	mov.u32 	%r26, %r17;
	@%p3 bra 	BB0_5;

BB0_4:
	mov.u32 	%r7, %r26;
	mov.u64 	%rd5, %rd18;
	ld.global.f64 	%fd9, [%rd17];
	ld.global.f64 	%fd10, [%rd5];
	sub.f64 	%fd11, %fd10, %fd9;
	fma.rn.f64 	%fd15, %fd11, %fd11, %fd15;
	add.s64 	%rd6, %rd5, 8;
	add.s64 	%rd17, %rd17, 8;
	add.s32 	%r8, %r7, 1;
	setp.lt.s32	%p4, %r8, %r13;
	mov.u64 	%rd18, %rd6;
	mov.f64 	%fd14, %fd15;
	mov.u32 	%r26, %r8;
	@%p4 bra 	BB0_4;

BB0_5:
	setp.lt.f64	%p5, %fd14, %fd12;
	selp.f64	%fd12, %fd14, %fd12, %p5;
	selp.b32	%r27, %r22, %r27, %p5;
	add.s32 	%r22, %r22, 1;
	setp.lt.s32	%p6, %r22, %r12;
	mov.u32 	%r25, %r27;
	@%p6 bra 	BB0_3;

BB0_6:
	cvta.to.global.u64 	%rd14, %rd9;
	mul.wide.s32 	%rd15, %r4, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.u32 	[%rd16], %r25;

BB0_7:
	ret;
}

	// .globl	getClusterCentroidsMod
.visible .entry getClusterCentroidsMod(
	.param .u32 getClusterCentroidsMod_param_0,
	.param .u64 getClusterCentroidsMod_param_1,
	.param .u64 getClusterCentroidsMod_param_2,
	.param .u64 getClusterCentroidsMod_param_3,
	.param .u64 getClusterCentroidsMod_param_4,
	.param .u64 getClusterCentroidsMod_param_5,
	.param .u32 getClusterCentroidsMod_param_6,
	.param .u32 getClusterCentroidsMod_param_7
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<22>;
	.reg .b64 	%rd<34>;


	ld.param.u32 	%r16, [getClusterCentroidsMod_param_0];
	ld.param.u64 	%rd11, [getClusterCentroidsMod_param_1];
	ld.param.u64 	%rd12, [getClusterCentroidsMod_param_2];
	ld.param.u64 	%rd13, [getClusterCentroidsMod_param_3];
	ld.param.u64 	%rd15, [getClusterCentroidsMod_param_4];
	ld.param.u64 	%rd14, [getClusterCentroidsMod_param_5];
	ld.param.u32 	%r17, [getClusterCentroidsMod_param_6];
	ld.param.u32 	%r18, [getClusterCentroidsMod_param_7];
	cvta.to.global.u64 	%rd1, %rd15;
	mul.lo.s32 	%r1, %r18, %r17;
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ntid.x;
	setp.ge.s32	%p1, %r2, %r1;
	@%p1 bra 	BB1_3;

	mov.u32 	%r26, %r2;

BB1_2:
	mov.u32 	%r4, %r26;
	mul.wide.s32 	%rd16, %r4, 8;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f64 	%fd8, [%rd17];
	mov.u64 	%rd18, local_means;
	add.s64 	%rd19, %rd18, %rd16;
	st.shared.f64 	[%rd19], %fd8;
	add.s32 	%r5, %r3, %r4;
	setp.lt.s32	%p2, %r5, %r1;
	mov.u32 	%r26, %r5;
	@%p2 bra 	BB1_2;

BB1_3:
	bar.sync 	0;
	mov.u32 	%r6, %ctaid.x;
	mad.lo.s32 	%r7, %r6, %r3, %r2;
	setp.ge.s32	%p3, %r7, %r16;
	@%p3 bra 	BB1_12;

	cvt.s64.s32	%rd2, %r7;
	mov.u32 	%r29, 0;
	setp.lt.s32	%p4, %r17, 1;
	@%p4 bra 	BB1_11;

	cvta.to.global.u64 	%rd20, %rd11;
	cvta.to.global.u64 	%rd21, %rd12;
	cvta.to.global.u64 	%rd3, %rd14;
	shl.b64 	%rd22, %rd2, 3;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.f64 	%fd1, [%rd23];
	mul.lo.s32 	%r23, %r18, %r7;
	mul.wide.s32 	%rd24, %r23, 8;
	add.s64 	%rd4, %rd20, %rd24;
	mov.f64 	%fd18, 0d7FEFFFFFFFFFFFFF;
	mov.u32 	%r29, 0;
	mov.u32 	%r27, %r29;

BB1_6:
	mul.lo.s32 	%r24, %r18, %r27;
	mul.wide.s32 	%rd25, %r24, 8;
	mov.u64 	%rd26, local_means;
	add.s64 	%rd5, %rd26, %rd25;
	mul.wide.s32 	%rd27, %r27, 8;
	add.s64 	%rd28, %rd3, %rd27;
	ld.global.f64 	%fd10, [%rd28];
	sub.f64 	%fd11, %fd10, %fd1;
	mul.f64 	%fd12, %fd11, %fd11;
	setp.geu.f64	%p5, %fd12, %fd18;
	@%p5 bra 	BB1_10;

	mov.u64 	%rd32, %rd5;
	mov.f64 	%fd20, 0d0000000000000000;
	mov.f64 	%fd21, %fd20;
	mov.u32 	%r28, 0;
	setp.lt.s32	%p6, %r18, 1;
	mov.u64 	%rd33, %rd4;
	@%p6 bra 	BB1_9;

BB1_8:
	mov.u64 	%rd8, %rd33;
	ld.shared.f64 	%fd15, [%rd32];
	ld.global.f64 	%fd16, [%rd8];
	sub.f64 	%fd17, %fd16, %fd15;
	fma.rn.f64 	%fd21, %fd17, %fd17, %fd21;
	add.s64 	%rd9, %rd8, 8;
	add.s64 	%rd32, %rd32, 8;
	add.s32 	%r28, %r28, 1;
	setp.lt.s32	%p7, %r28, %r18;
	mov.u64 	%rd33, %rd9;
	mov.f64 	%fd20, %fd21;
	@%p7 bra 	BB1_8;

BB1_9:
	setp.lt.f64	%p8, %fd20, %fd18;
	selp.f64	%fd18, %fd20, %fd18, %p8;
	selp.b32	%r29, %r27, %r29, %p8;

BB1_10:
	add.s32 	%r27, %r27, 1;
	setp.lt.s32	%p9, %r27, %r17;
	@%p9 bra 	BB1_6;

BB1_11:
	cvta.to.global.u64 	%rd29, %rd13;
	shl.b64 	%rd30, %rd2, 2;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.u32 	[%rd31], %r29;

BB1_12:
	ret;
}

	// .globl	calculateIntermediates
.visible .entry calculateIntermediates(
	.param .u32 calculateIntermediates_param_0,
	.param .u64 calculateIntermediates_param_1,
	.param .u64 calculateIntermediates_param_2,
	.param .u64 calculateIntermediates_param_3,
	.param .u64 calculateIntermediates_param_4,
	.param .u64 calculateIntermediates_param_5,
	.param .u32 calculateIntermediates_param_6,
	.param .u32 calculateIntermediates_param_7
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<49>;
	.reg .f64 	%fd<26>;
	.reg .b64 	%rd<25>;


	ld.param.u32 	%r24, [calculateIntermediates_param_0];
	ld.param.u64 	%rd10, [calculateIntermediates_param_1];
	ld.param.u64 	%rd14, [calculateIntermediates_param_2];
	ld.param.u64 	%rd11, [calculateIntermediates_param_3];
	ld.param.u64 	%rd12, [calculateIntermediates_param_4];
	ld.param.u64 	%rd13, [calculateIntermediates_param_5];
	ld.param.u32 	%r22, [calculateIntermediates_param_6];
	ld.param.u32 	%r23, [calculateIntermediates_param_7];
	cvta.to.global.u64 	%rd1, %rd14;
	mul.hi.s32 	%r25, %r24, -1851608123;
	add.s32 	%r26, %r25, %r24;
	shr.u32 	%r27, %r26, 31;
	shr.s32 	%r28, %r26, 8;
	add.s32 	%r1, %r28, %r27;
	add.s32 	%r29, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r3, %r2, %r29;
	add.s32 	%r30, %r3, %r29;
	min.s32 	%r4, %r24, %r30;
	mov.u32 	%r41, %tid.y;
	setp.ge.s32	%p1, %r41, %r22;
	@%p1 bra 	BB2_14;

	cvta.to.global.u64 	%rd2, %rd13;
	cvta.to.global.u64 	%rd3, %rd12;
	cvta.to.global.u64 	%rd4, %rd10;
	cvta.to.global.u64 	%rd5, %rd11;
	mov.u32 	%r6, %tid.x;
	mov.u32 	%r7, %ntid.y;
	mul.lo.s32 	%r8, %r2, %r22;
	mov.u32 	%r9, %ntid.x;
	mul.lo.s32 	%r32, %r2, %r29;
	mul.wide.s32 	%rd15, %r32, 4;
	add.s64 	%rd6, %rd1, %rd15;

BB2_2:
	setp.ge.s32	%p2, %r6, %r23;
	@%p2 bra 	BB2_13;

	add.s32 	%r33, %r41, %r8;
	mul.wide.u32 	%rd16, %r33, 4;
	add.s64 	%rd7, %rd5, %rd16;
	mul.lo.s32 	%r11, %r33, %r23;
	mov.u32 	%r42, %r6;

BB2_4:
	mov.u32 	%r12, %r42;
	setp.ne.s32	%p3, %r12, 0;
	@%p3 bra 	BB2_8;

	mov.u32 	%r44, 0;
	mov.u32 	%r45, %r44;
	setp.ge.s32	%p4, %r3, %r4;
	mov.u64 	%rd24, %rd6;
	mov.u32 	%r48, %r3;
	@%p4 bra 	BB2_7;

BB2_6:
	mov.u32 	%r13, %r48;
	mov.u64 	%rd8, %rd24;
	ld.global.u32 	%r36, [%rd8];
	setp.eq.s32	%p5, %r36, %r41;
	selp.u32	%r37, 1, 0, %p5;
	add.s32 	%r45, %r37, %r45;
	add.s64 	%rd9, %rd8, 4;
	add.s32 	%r16, %r13, 1;
	setp.lt.s32	%p6, %r16, %r4;
	mov.u64 	%rd24, %rd9;
	mov.u32 	%r44, %r45;
	mov.u32 	%r48, %r16;
	@%p6 bra 	BB2_6;

BB2_7:
	st.global.u32 	[%rd7], %r44;

BB2_8:
	mov.f64 	%fd23, 0d0000000000000000;
	mov.f64 	%fd17, %fd23;
	mov.f64 	%fd24, %fd23;
	mov.f64 	%fd18, %fd23;
	setp.ge.s32	%p7, %r3, %r4;
	mov.u32 	%r47, %r3;
	@%p7 bra 	BB2_12;

BB2_9:
	mov.f64 	%fd20, %fd24;
	mov.f64 	%fd25, %fd20;
	mov.f64 	%fd14, %fd18;
	mov.f64 	%fd19, %fd14;
	mul.wide.s32 	%rd17, %r47, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.u32 	%r38, [%rd18];
	setp.ne.s32	%p8, %r38, %r41;
	@%p8 bra 	BB2_11;

	mad.lo.s32 	%r39, %r47, %r23, %r12;
	mul.wide.s32 	%rd19, %r39, 8;
	add.s64 	%rd20, %rd4, %rd19;
	ld.global.f64 	%fd13, [%rd20];
	add.f64 	%fd25, %fd25, %fd13;
	fma.rn.f64 	%fd19, %fd13, %fd13, %fd19;

BB2_11:
	mov.f64 	%fd24, %fd25;
	mov.f64 	%fd18, %fd19;
	add.s32 	%r47, %r47, 1;
	setp.lt.s32	%p9, %r47, %r4;
	mov.f64 	%fd17, %fd18;
	mov.f64 	%fd23, %fd24;
	@%p9 bra 	BB2_9;

BB2_12:
	add.s32 	%r40, %r12, %r11;
	mul.wide.s32 	%rd21, %r40, 8;
	add.s64 	%rd22, %rd3, %rd21;
	st.global.f64 	[%rd22], %fd23;
	add.s64 	%rd23, %rd2, %rd21;
	st.global.f64 	[%rd23], %fd17;
	add.s32 	%r20, %r9, %r12;
	setp.lt.s32	%p10, %r20, %r23;
	mov.u32 	%r42, %r20;
	@%p10 bra 	BB2_4;

BB2_13:
	add.s32 	%r41, %r7, %r41;
	setp.lt.s32	%p11, %r41, %r22;
	@%p11 bra 	BB2_2;

BB2_14:
	ret;
}

	// .globl	calculateIntermediatesMod
.visible .entry calculateIntermediatesMod(
	.param .u32 calculateIntermediatesMod_param_0,
	.param .u64 calculateIntermediatesMod_param_1,
	.param .u64 calculateIntermediatesMod_param_2,
	.param .u64 calculateIntermediatesMod_param_3,
	.param .u64 calculateIntermediatesMod_param_4,
	.param .u32 calculateIntermediatesMod_param_5,
	.param .u32 calculateIntermediatesMod_param_6
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<49>;
	.reg .f64 	%fd<14>;
	.reg .b64 	%rd<22>;


	ld.param.u32 	%r23, [calculateIntermediatesMod_param_0];
	ld.param.u64 	%rd8, [calculateIntermediatesMod_param_1];
	ld.param.u64 	%rd11, [calculateIntermediatesMod_param_2];
	ld.param.u64 	%rd9, [calculateIntermediatesMod_param_3];
	ld.param.u64 	%rd10, [calculateIntermediatesMod_param_4];
	ld.param.u32 	%r21, [calculateIntermediatesMod_param_5];
	ld.param.u32 	%r22, [calculateIntermediatesMod_param_6];
	cvta.to.global.u64 	%rd1, %rd11;
	mul.hi.s32 	%r24, %r23, -1851608123;
	add.s32 	%r25, %r24, %r23;
	shr.u32 	%r26, %r25, 31;
	shr.s32 	%r27, %r25, 8;
	add.s32 	%r1, %r27, %r26;
	add.s32 	%r28, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r3, %r2, %r28;
	add.s32 	%r29, %r3, %r28;
	min.s32 	%r4, %r23, %r29;
	mov.u32 	%r41, %tid.y;
	setp.ge.s32	%p1, %r41, %r21;
	@%p1 bra 	BB3_14;

	cvta.to.global.u64 	%rd2, %rd10;
	cvta.to.global.u64 	%rd3, %rd8;
	mov.u32 	%r6, %tid.x;
	mul.lo.s32 	%r7, %r2, %r21;
	mov.u32 	%r8, %ntid.x;
	mul.lo.s32 	%r31, %r2, %r28;
	mul.wide.s32 	%rd12, %r31, 4;
	add.s64 	%rd4, %rd1, %rd12;
	cvta.to.global.u64 	%rd13, %rd9;

BB3_2:
	setp.ge.s32	%p2, %r6, %r22;
	@%p2 bra 	BB3_13;

	add.s32 	%r32, %r41, %r7;
	mul.wide.u32 	%rd14, %r32, 4;
	add.s64 	%rd5, %rd13, %rd14;
	mul.lo.s32 	%r10, %r32, %r22;
	mov.u32 	%r42, %r6;

BB3_4:
	mov.u32 	%r11, %r42;
	setp.ne.s32	%p3, %r11, 0;
	@%p3 bra 	BB3_8;

	mov.u32 	%r44, 0;
	mov.u32 	%r45, %r44;
	setp.ge.s32	%p4, %r3, %r4;
	mov.u64 	%rd21, %rd4;
	mov.u32 	%r48, %r3;
	@%p4 bra 	BB3_7;

BB3_6:
	mov.u32 	%r12, %r48;
	mov.u64 	%rd6, %rd21;
	ld.global.u32 	%r35, [%rd6];
	setp.eq.s32	%p5, %r35, %r41;
	selp.u32	%r36, 1, 0, %p5;
	add.s32 	%r45, %r36, %r45;
	add.s64 	%rd7, %rd6, 4;
	add.s32 	%r15, %r12, 1;
	setp.lt.s32	%p6, %r15, %r4;
	mov.u64 	%rd21, %rd7;
	mov.u32 	%r44, %r45;
	mov.u32 	%r48, %r15;
	@%p6 bra 	BB3_6;

BB3_7:
	st.global.u32 	[%rd5], %r44;

BB3_8:
	mov.f64 	%fd11, 0d0000000000000000;
	mov.f64 	%fd12, %fd11;
	setp.ge.s32	%p7, %r3, %r4;
	mov.u32 	%r47, %r3;
	@%p7 bra 	BB3_12;

BB3_9:
	mov.f64 	%fd8, %fd12;
	mov.f64 	%fd13, %fd8;
	mul.wide.s32 	%rd15, %r47, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.u32 	%r37, [%rd16];
	setp.ne.s32	%p8, %r37, %r41;
	@%p8 bra 	BB3_11;

	mad.lo.s32 	%r38, %r47, %r22, %r11;
	mul.wide.s32 	%rd17, %r38, 8;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.f64 	%fd7, [%rd18];
	add.f64 	%fd13, %fd13, %fd7;

BB3_11:
	mov.f64 	%fd12, %fd13;
	add.s32 	%r47, %r47, 1;
	setp.lt.s32	%p9, %r47, %r4;
	mov.f64 	%fd11, %fd12;
	@%p9 bra 	BB3_9;

BB3_12:
	add.s32 	%r39, %r11, %r10;
	mul.wide.s32 	%rd19, %r39, 8;
	add.s64 	%rd20, %rd2, %rd19;
	st.global.f64 	[%rd20], %fd11;
	add.s32 	%r19, %r8, %r11;
	setp.lt.s32	%p10, %r19, %r22;
	mov.u32 	%r42, %r19;
	@%p10 bra 	BB3_4;

BB3_13:
	mov.u32 	%r40, %ntid.y;
	add.s32 	%r41, %r40, %r41;
	setp.lt.s32	%p11, %r41, %r21;
	@%p11 bra 	BB3_2;

BB3_14:
	ret;
}

	// .globl	calculateFinal
.visible .entry calculateFinal(
	.param .u32 calculateFinal_param_0,
	.param .u64 calculateFinal_param_1,
	.param .u64 calculateFinal_param_2,
	.param .u64 calculateFinal_param_3,
	.param .u64 calculateFinal_param_4,
	.param .u64 calculateFinal_param_5,
	.param .u64 calculateFinal_param_6,
	.param .u32 calculateFinal_param_7,
	.param .u32 calculateFinal_param_8
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<39>;


	ld.param.u64 	%rd23, [calculateFinal_param_1];
	ld.param.u64 	%rd28, [calculateFinal_param_2];
	ld.param.u64 	%rd24, [calculateFinal_param_3];
	ld.param.u64 	%rd25, [calculateFinal_param_4];
	ld.param.u64 	%rd26, [calculateFinal_param_5];
	ld.param.u64 	%rd27, [calculateFinal_param_6];
	ld.param.u32 	%r23, [calculateFinal_param_7];
	ld.param.u32 	%r24, [calculateFinal_param_8];
	cvta.to.global.u64 	%rd1, %rd28;
	mov.u32 	%r25, %ctaid.x;
	setp.ne.s32	%p1, %r25, 0;
	@%p1 bra 	BB4_13;

	mov.u32 	%r1, %tid.y;
	setp.ge.s32	%p2, %r1, %r23;
	@%p2 bra 	BB4_13;

	cvta.to.global.u64 	%rd2, %rd27;
	cvta.to.global.u64 	%rd3, %rd24;
	cvta.to.global.u64 	%rd4, %rd26;
	cvta.to.global.u64 	%rd5, %rd25;
	cvta.to.global.u64 	%rd6, %rd23;
	mov.u32 	%r2, %tid.x;
	mul.lo.s32 	%r3, %r23, 450;
	mul.lo.s32 	%r27, %r24, %r23;
	mul.lo.s32 	%r28, %r27, 450;
	mul.wide.s32 	%rd29, %r28, 8;
	add.s64 	%rd7, %rd1, %rd29;
	mov.u32 	%r4, %ntid.x;
	mul.wide.s32 	%rd8, %r23, 4;
	mad.lo.s32 	%r5, %r1, %r24, %r2;
	mov.u32 	%r6, %ntid.y;
	mul.lo.s32 	%r7, %r6, %r24;
	mul.wide.s32 	%rd9, %r27, 8;
	mov.u32 	%r34, 0;
	mov.u32 	%r40, %r1;

BB4_3:
	mov.u32 	%r38, %r40;
	mov.u32 	%r9, %r38;
	setp.ge.s32	%p3, %r2, %r24;
	@%p3 bra 	BB4_12;

	mad.lo.s32 	%r10, %r7, %r34, %r5;
	mad.lo.s32 	%r30, %r6, %r34, %r1;
	mul.wide.s32 	%rd30, %r30, 4;
	add.s64 	%rd10, %rd6, %rd30;
	mul.wide.s32 	%rd31, %r9, 4;
	add.s64 	%rd11, %rd5, %rd31;
	mul.lo.s32 	%r11, %r9, %r24;
	mov.u32 	%r35, 0;
	mov.u32 	%r36, %r2;

BB4_5:
	mov.u32 	%r13, %r36;
	setp.ge.s32	%p4, %r9, %r3;
	setp.ne.s32	%p5, %r13, 0;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	BB4_8;

	ld.global.u32 	%r37, [%rd11];
	mov.u64 	%rd36, %rd10;
	mov.u32 	%r39, %r9;

BB4_7:
	mov.u32 	%r16, %r39;
	mov.u64 	%rd12, %rd36;
	ld.global.u32 	%r31, [%rd12];
	add.s32 	%r37, %r37, %r31;
	st.global.u32 	[%rd11], %r37;
	add.s64 	%rd13, %rd12, %rd8;
	add.s32 	%r18, %r16, %r23;
	setp.lt.s32	%p7, %r18, %r3;
	mov.u64 	%rd36, %rd13;
	mov.u32 	%r39, %r18;
	@%p7 bra 	BB4_7;

BB4_8:
	add.s32 	%r32, %r13, %r11;
	cvt.s64.s32	%rd14, %r32;
	mul.wide.s32 	%rd32, %r32, 8;
	add.s64 	%rd33, %rd1, %rd32;
	setp.ge.u64	%p8, %rd33, %rd7;
	@%p8 bra 	BB4_11;

	mad.lo.s32 	%r33, %r4, %r35, %r10;
	mul.wide.s32 	%rd34, %r33, 8;
	add.s64 	%rd38, %rd3, %rd34;
	add.s64 	%rd37, %rd1, %rd34;
	shl.b64 	%rd35, %rd14, 3;
	add.s64 	%rd17, %rd4, %rd35;
	add.s64 	%rd18, %rd2, %rd35;

BB4_10:
	ld.global.f64 	%fd1, [%rd17];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd17], %fd3;
	ld.global.f64 	%fd4, [%rd18];
	ld.global.f64 	%fd5, [%rd38];
	add.f64 	%fd6, %fd5, %fd4;
	st.global.f64 	[%rd18], %fd6;
	add.s64 	%rd38, %rd38, %rd9;
	add.s64 	%rd37, %rd37, %rd9;
	setp.lt.u64	%p9, %rd37, %rd7;
	@%p9 bra 	BB4_10;

BB4_11:
	add.s32 	%r19, %r4, %r13;
	setp.lt.s32	%p10, %r19, %r24;
	add.s32 	%r35, %r35, 1;
	mov.u32 	%r36, %r19;
	@%p10 bra 	BB4_5;

BB4_12:
	add.s32 	%r21, %r6, %r9;
	setp.lt.s32	%p11, %r21, %r23;
	add.s32 	%r34, %r34, 1;
	mov.u32 	%r40, %r21;
	@%p11 bra 	BB4_3;

BB4_13:
	ret;
}

	// .globl	calculateFinalMod
.visible .entry calculateFinalMod(
	.param .u32 calculateFinalMod_param_0,
	.param .u64 calculateFinalMod_param_1,
	.param .u64 calculateFinalMod_param_2,
	.param .u64 calculateFinalMod_param_3,
	.param .u64 calculateFinalMod_param_4,
	.param .u32 calculateFinalMod_param_5,
	.param .u32 calculateFinalMod_param_6
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<6>;
	.reg .b64 	%rd<30>;


	ld.param.u64 	%rd17, [calculateFinalMod_param_1];
	ld.param.u64 	%rd20, [calculateFinalMod_param_2];
	ld.param.u64 	%rd18, [calculateFinalMod_param_3];
	ld.param.u64 	%rd19, [calculateFinalMod_param_4];
	ld.param.u32 	%r23, [calculateFinalMod_param_5];
	ld.param.u32 	%r24, [calculateFinalMod_param_6];
	cvta.to.global.u64 	%rd1, %rd20;
	mov.u32 	%r25, %ctaid.x;
	setp.ne.s32	%p1, %r25, 0;
	@%p1 bra 	BB5_13;

	mov.u32 	%r1, %tid.y;
	setp.ge.s32	%p2, %r1, %r23;
	@%p2 bra 	BB5_13;

	cvta.to.global.u64 	%rd2, %rd19;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd17;
	mov.u32 	%r2, %tid.x;
	mul.lo.s32 	%r3, %r23, 450;
	mul.lo.s32 	%r27, %r24, %r23;
	mul.lo.s32 	%r28, %r27, 450;
	mul.wide.s32 	%rd21, %r28, 8;
	add.s64 	%rd5, %rd1, %rd21;
	mov.u32 	%r4, %ntid.x;
	mul.wide.s32 	%rd6, %r23, 4;
	mad.lo.s32 	%r5, %r1, %r24, %r2;
	mov.u32 	%r6, %ntid.y;
	mul.lo.s32 	%r7, %r6, %r24;
	mul.wide.s32 	%rd7, %r27, 8;
	mov.u32 	%r34, 0;
	mov.u32 	%r40, %r1;

BB5_3:
	mov.u32 	%r38, %r40;
	mov.u32 	%r9, %r38;
	setp.ge.s32	%p3, %r2, %r24;
	@%p3 bra 	BB5_12;

	mad.lo.s32 	%r10, %r7, %r34, %r5;
	mad.lo.s32 	%r30, %r6, %r34, %r1;
	mul.wide.s32 	%rd22, %r30, 4;
	add.s64 	%rd8, %rd4, %rd22;
	mul.wide.s32 	%rd23, %r9, 4;
	add.s64 	%rd9, %rd3, %rd23;
	mul.lo.s32 	%r11, %r9, %r24;
	mov.u32 	%r35, 0;
	mov.u32 	%r36, %r2;

BB5_5:
	mov.u32 	%r13, %r36;
	setp.ge.s32	%p4, %r9, %r3;
	setp.ne.s32	%p5, %r13, 0;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	BB5_8;

	ld.global.u32 	%r37, [%rd9];
	mov.u64 	%rd28, %rd8;
	mov.u32 	%r39, %r9;

BB5_7:
	mov.u32 	%r16, %r39;
	mov.u64 	%rd10, %rd28;
	ld.global.u32 	%r31, [%rd10];
	add.s32 	%r37, %r37, %r31;
	st.global.u32 	[%rd9], %r37;
	add.s64 	%rd11, %rd10, %rd6;
	add.s32 	%r18, %r16, %r23;
	setp.lt.s32	%p7, %r18, %r3;
	mov.u64 	%rd28, %rd11;
	mov.u32 	%r39, %r18;
	@%p7 bra 	BB5_7;

BB5_8:
	add.s32 	%r32, %r13, %r11;
	cvt.s64.s32	%rd12, %r32;
	mul.wide.s32 	%rd24, %r32, 8;
	add.s64 	%rd25, %rd1, %rd24;
	setp.ge.u64	%p8, %rd25, %rd5;
	@%p8 bra 	BB5_11;

	mad.lo.s32 	%r33, %r4, %r35, %r10;
	mul.wide.s32 	%rd26, %r33, 8;
	add.s64 	%rd29, %rd1, %rd26;
	shl.b64 	%rd27, %rd12, 3;
	add.s64 	%rd14, %rd2, %rd27;
	ld.global.f64 	%fd5, [%rd14];

BB5_10:
	ld.global.f64 	%fd4, [%rd29];
	add.f64 	%fd5, %fd4, %fd5;
	st.global.f64 	[%rd14], %fd5;
	add.s64 	%rd29, %rd29, %rd7;
	setp.lt.u64	%p9, %rd29, %rd5;
	@%p9 bra 	BB5_10;

BB5_11:
	add.s32 	%r19, %r4, %r13;
	setp.lt.s32	%p10, %r19, %r24;
	add.s32 	%r35, %r35, 1;
	mov.u32 	%r36, %r19;
	@%p10 bra 	BB5_5;

BB5_12:
	add.s32 	%r21, %r6, %r9;
	setp.lt.s32	%p11, %r21, %r23;
	add.s32 	%r34, %r34, 1;
	mov.u32 	%r40, %r21;
	@%p11 bra 	BB5_3;

BB5_13:
	ret;
}


